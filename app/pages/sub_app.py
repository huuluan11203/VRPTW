# pages/02_quan_ly_cache_tuyen.py
from pathlib import Path
import json, math, datetime, os, shutil
import pandas as pd
import streamlit as st
import folium
from streamlit_folium import st_folium
# =============== C·∫§U H√åNH ===============
st.set_page_config(page_title="Xem tuy·∫øn (route_geoms / route_geoms1)", page_icon="üß≠", layout="wide")
st.markdown("<h2 style='text-align:center;margin:0.25rem 0 1rem 0'>Xem tuy·∫øn t·ª´ CSV</h2>", unsafe_allow_html=True)

APP_DIR = Path(__file__).resolve().parents[1]
RESULTS_DIR = APP_DIR / "results"
GEOMS_DIR_DEFAULT = RESULTS_DIR / "route_geoms"
GEOMS_DIR_NEW = RESULTS_DIR / "route_geoms1"
OSRM_URL = os.environ.get("OSRM_URL", "https://router.project-osrm.org")

# üü¢ CH·ªàNH L·∫†I ƒê√ÇY CHO PH√ô H·ª¢P C·∫§U TR√öC M·ªöI
PROJECT_ROOT = APP_DIR              # v√¨ solver n·∫±m trong app/
SOLVER_PKG = APP_DIR / "solver"     # ƒë∆∞·ªùng d·∫´n t·ªõi app/solver
# √âp solver d√πng OSRM public thay v√¨ localhost:5000
# --- Force all OSRM calls to public server + fix lat,lon -> lon,lat ---
import re, requests as _rq

_OSRM_PUBLIC = "https://router.project-osrm.org"  # base host (kh√¥ng c√≥ /route hay /table)

# b·∫£n g·ªëc
_orig_request = _rq.sessions.Session.request

_coord_pair_re = re.compile(r"(-?\d+(?:\.\d+)?),(-?\d+(?:\.\d+)?)")

def _swap_if_latlon(x: str) -> str:
    """
    V·ªõi chu·ªói 'a,b' n·∫øu |a|<=90 v√† |b|<=180 th√¨ coi l√† lat,lon -> tr·∫£ 'b,a' (lon,lat).
    Ng∆∞·ª£c l·∫°i gi·ªØ nguy√™n.
    """
    try:
        a = float(x.group(1)); b = float(x.group(2))
        if abs(a) <= 90 and abs(b) <= 180:
            return f"{b},{a}"           # lon,lat
        return x.group(0)
    except Exception:
        return x.group(0)

def _fix_osrm_url(url: str) -> str:
    # 1) chuy·ªÉn localhost:5000 / 127.0.0.1:5000 sang public OSRM
    if url.startswith("http://localhost:5000"):
        url = _OSRM_PUBLIC + url[len("http://localhost:5000"):]
    elif url.startswith("http://127.0.0.1:5000"):
        url = _OSRM_PUBLIC + url[len("http://127.0.0.1:5000"):]
    elif url.startswith("http://0.0.0.0:5000"):
        url = _OSRM_PUBLIC + url[len("http://0.0.0.0:5000"):]
    # 2) ch·ªâ s·ª≠a to·∫° ƒë·ªô cho endpoint OSRM /route|/table
    if "/route/v1/driving/" in url or "/table/v1/driving/" in url:
        # t√°ch query ?... ƒë·ªÉ ch·ªâ x·ª≠ l√Ω ph·∫ßn to·∫° ƒë·ªô
        if "?" in url:
            base, qs = url.split("?", 1)
            base = _coord_pair_re.sub(_swap_if_latlon, base)
            return f"{base}?{qs}"
        else:
            return _coord_pair_re.sub(_swap_if_latlon, url)
    return url

def _patched_request(self, method, url, *args, **kwargs):
    url = _fix_osrm_url(url)
    return _orig_request(self, method, url, *args, **kwargs)

# √Åp d·ª•ng patch cho to√†n b·ªô requests (bao g·ªìm ph·∫ßn solver)
_rq.sessions.Session.request = _patched_request


def _import_solver():
    """
    Tr·∫£ v·ªÅ h√†m run_vrptw_advanced t·ª´ app/solver/vrptw_solver.py
    v√† t·ª± x·ª≠ l√Ω import tuy·ªát ƒë·ªëi 'from data_processing import ...'.
    """
    import sys, importlib, importlib.util

    # ƒê·∫£m b·∫£o app/solver c√≥ trong sys.path
    solver_path_str = str(SOLVER_PKG)
    if solver_path_str not in sys.path:
        sys.path.insert(0, solver_path_str)

    # N·∫°p tr∆∞·ªõc data_processing (ƒë·ªÉ solver import ƒë∆∞·ª£c)
    dp_path = SOLVER_PKG / "data_processing.py"
    if dp_path.exists():
        spec_dp = importlib.util.spec_from_file_location("data_processing", dp_path)
        dp_mod = importlib.util.module_from_spec(spec_dp)
        spec_dp.loader.exec_module(dp_mod)
        sys.modules["data_processing"] = dp_mod

    # Import vrptw_solver
    solver_file = SOLVER_PKG / "vrptw_solver.py"
    if not solver_file.exists():
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file solver: {solver_file}")

    spec = importlib.util.spec_from_file_location("vrptw_solver", solver_file)
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)

    # L·∫•y h√†m ch·∫°y ch√≠nh
    if hasattr(mod, "run_vrptw_advanced"):
        return mod.run_vrptw_advanced
    elif hasattr(mod, "run_solver"):
        return mod.run_solver
    else:
        raise AttributeError("Kh√¥ng t√¨m th·∫•y h√†m run_vrptw_advanced ho·∫∑c run_solver trong vrptw_solver.py")




# ƒë·ªïi CWD t·∫°m th·ªùi (nhi·ªÅu solver d√πng ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi)
from contextlib import contextmanager
@contextmanager
def _pushd(path: Path):
    old = Path.cwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(old)

def _run_solver_with_csv(csv_path: Path, time_limit: float):
    """
    G·ªçi solver v·ªõi CSV ƒë√£ ch·ªçn.
    - Solver nh·∫≠n `customers_file` l√† basename (v√≠ d·ª• temp_cus.csv)
    - T·∫°m chdir sang PROJECT_ROOT ƒë·ªÉ t∆∞∆°ng th√≠ch ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi
    """
    run_vrptw_advanced = _import_solver()
    customers_arg = os.path.basename(str(csv_path))
    with _pushd(PROJECT_ROOT):
        return run_vrptw_advanced(
            customers_file=customers_arg,
            max_iter=50000,
            time_limit=float(time_limit),
            use_cache=True,
        )

def _find_and_copy_solution_json() -> Path | None:
    """
    T√¨m file solution JSON ·ªü nhi·ªÅu t√™n/ƒë∆∞·ªùng d·∫´n, r·ªìi copy v·ªÅ app/results/.
    H·ªó tr·ª£ c√°c t√™n: solution_advanced.json, solution_demo.json.
    """
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)

    possible_names = {"solution_advanced.json", "solution_demo.json"}

    # 1) N·∫øu ƒë√£ c√≥ s·∫µn ·ªü ƒë√≠ch
    for n in possible_names:
        p = RESULTS_DIR / n
        if p.exists():
            return p

    # 2) C√°c v·ªã tr√≠ hay g·∫∑p
    candidates = []
    for n in possible_names:
        candidates += [
            PROJECT_ROOT / n,
            PROJECT_ROOT / "results" / n,
            SOLVER_PKG / n,
            SOLVER_PKG / "results" / n,
        ]

    # 3) Qu√©t to√†n d·ª± √°n (l·∫•y file m·ªõi nh·∫•t n·∫øu c√≥ nhi·ªÅu)
    newest, newest_mtime = None, -1
    try:
        for p in candidates + list(PROJECT_ROOT.rglob("solution_*.json")):
            if p and p.exists() and p.is_file():
                mt = p.stat().st_mtime
                if mt > newest_mtime:
                    newest, newest_mtime = p, mt
    except Exception:
        pass

    if newest:
        target = RESULTS_DIR / newest.name
        shutil.copy2(newest, target)
        return target

    return None



# =============== STATE ===============
if "cache_view_keys" not in st.session_state:
    st.session_state.cache_view_keys = []
if "last_run_keys" not in st.session_state:
    st.session_state.last_run_keys = []
if "selected_csv" not in st.session_state:
    st.session_state.selected_csv = None
if "active_geom_dir" not in st.session_state:
    st.session_state.active_geom_dir = str(GEOMS_DIR_DEFAULT)

# =============== TI·ªÜN √çCH ===============
def _human_size(n: int):
    if not n: return "0 B"
    units = ["B","KB","MB","GB","TB"]
    i = int(math.floor(math.log(max(n,1), 1024)))
    return f"{n/1024**i:.1f} {units[i]}"

def _read_distance_km(folder: Path, key: str):
    p = folder / f"{key}.distance"
    try:
        return float(p.read_text(encoding="utf-8").strip())
    except Exception:
        return None

def _list_cache_pairs(folder: Path) -> pd.DataFrame:
    if not folder.exists():
        return pd.DataFrame()
    files = list(folder.glob("*"))
    meta = {}
    for p in files:
        stem = p.stem
        if stem not in meta:
            meta[stem] = {
                "key": stem,
                "has_geojson": False, "geojson_size": 0, "geojson_mtime": None,
                "has_distance": False, "distance_size": 0, "distance_mtime": None,
            }
        if p.suffix.lower() == ".geojson":
            meta[stem]["has_geojson"] = True
            meta[stem]["geojson_size"] = p.stat().st_size
            meta[stem]["geojson_mtime"] = datetime.datetime.fromtimestamp(p.stat().st_mtime)
        elif p.suffix.lower() == ".distance":
            meta[stem]["has_distance"] = True
            meta[stem]["distance_size"] = p.stat().st_size
            meta[stem]["distance_mtime"] = datetime.datetime.fromtimestamp(p.stat().st_mtime)

    if not meta:
        return pd.DataFrame()
    df = pd.DataFrame(list(meta.values()))
    df["last_mtime"] = df[["geojson_mtime", "distance_mtime"]].max(axis=1)
    df["distance_km"] = [
        _read_distance_km(folder, k) if has else None
        for k, has in zip(df["key"], df["has_distance"])
    ]
    df = df.sort_values(by="last_mtime", ascending=False).reset_index(drop=True)
    df["route_name"] = df.index.map(lambda i: f"Route {i+1}")
    return df

def _coords_to_osrm_str(coords):  # coords = [(lat,lon),...]
    return ";".join(f"{lon},{lat}" for lat, lon in coords)

def _fetch_osrm_route(coords):
    """Tr·∫£ v·ªÅ (geometry_geojson, distance_km) ho·∫∑c (None, None)."""
    import requests
    if len(coords) < 2: return None, None
    url = f"{OSRM_URL}/route/v1/driving/{_coords_to_osrm_str(coords)}"
    params = {"overview":"full","geometries":"geojson","steps":"false"}
    try:
        r = requests.get(url, params=params, timeout=20)
        r.raise_for_status()
        data = r.json()
        if data.get("routes"):
            g = data["routes"][0]["geometry"]
            dkm = data["routes"][0]["distance"]/1000.0
            return g, dkm
    except Exception as e:
        st.warning(f"OSRM l·ªói: {e}")
    return None, None

def _load_csv_points(csv_path: Path) -> pd.DataFrame:
    """ƒê·ªçc CSV theo ƒë·ªãnh d·∫°ng temp_cus.csv (2 d√≤ng header NUM_VEHICLE/CAPACITY c√≥ th·ªÉ c√≥)."""
    with open(csv_path, "r", encoding="utf-8") as f:
        first = f.readline()
        second = f.readline()
    skip = 2 if first.startswith("NUM_VEHICLE") or second.startswith("CAPACITY") else 0
    df = pd.read_csv(csv_path, skiprows=skip)
    # Chu·∫©n ho√° t√™n c·ªôt
    if "lat" in df.columns and "Lat" not in df.columns: df["Lat"] = df["lat"]
    if "lon" in df.columns and "Long" not in df.columns: df["Long"] = df["lon"]
    if "id" in df.columns and "ID" not in df.columns: df["ID"] = df["id"]
    df["ID"] = pd.to_numeric(df["ID"], errors="coerce").astype(int)
    return df[["ID","Lat","Long"]].dropna()

def _build_route_geoms_from_solution(csv_path: Path, solution_json: Path, out_dir: Path):
    """ƒê·ªçc solution_advanced.json -> t·∫°o route_geoms1 (route_1/2/3...)."""
    points = _load_csv_points(csv_path)
    id2coord = {int(r.ID): (float(r.Lat), float(r.Long)) for _, r in points.iterrows()}
    if 0 not in id2coord:
        st.error("CSV thi·∫øu depot (ID=0). Kh√¥ng th·ªÉ t·∫°o tuy·∫øn.")
        return False

    data = json.loads(solution_json.read_text(encoding="utf-8"))
    routes = data.get("routes", [])
    if not routes:
        st.error("solution_advanced.json kh√¥ng c√≥ d·ªØ li·ªáu routes.")
        return False

    out_dir.mkdir(parents=True, exist_ok=True)

    created = 0
    for i, route_ids in enumerate(routes, start=1):
        coords = [id2coord[0]] + [id2coord[c] for c in route_ids if c in id2coord] + [id2coord[0]]
        geom, dkm = _fetch_osrm_route(coords)
        key = f"route_{i}"
        gj = out_dir / f"{key}.geojson"
        ds = out_dir / f"{key}.distance"
        if geom:
            gj.write_text(json.dumps(geom), encoding="utf-8")
        if dkm is not None:
            ds.write_text(f"{dkm}", encoding="utf-8")
        created += 1
    st.success(f"ƒê√£ t·∫°o {created} tuy·∫øn trong: {out_dir}")
    return True

# =============== GIAO DI·ªÜN ===============
left, right = st.columns([2,3])

with left:
    st.markdown("### 1) Ch·ªçn file CSV")
    UPLOAD_DIR = APP_DIR / "data" / "raw"
    UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
    available_csv = sorted([p.name for p in UPLOAD_DIR.glob("*.csv")])
    choice = st.radio("Ngu·ªìn d·ªØ li·ªáu:", ["üìÇ Ch·ªçn file c√≥ s·∫µn", "‚¨ÜÔ∏è Upload file m·ªõi"], horizontal=True)

    csv_path = None
    if choice == "üìÇ Ch·ªçn file c√≥ s·∫µn":
        if available_csv:
            default_idx = max(0, available_csv.index("test90.csv")) if "test90.csv" in available_csv else 0
            pick_name = st.selectbox("Ch·ªçn file CSV:", available_csv, index=default_idx)
            csv_path = UPLOAD_DIR / pick_name
            st.session_state.selected_csv = str(csv_path)
            st.success(f"ƒê√£ ch·ªçn file: {pick_name}")
        else:
            st.warning("‚ö†Ô∏è Ch∆∞a c√≥ file CSV n√†o trong `app/data/raw`.")
    else:
        up = st.file_uploader("T·∫£i l√™n file CSV m·ªõi", type=["csv"])
        if up is not None:
            csv_path = UPLOAD_DIR / up.name
            with open(csv_path, "wb") as f:
                f.write(up.getbuffer())
            st.session_state.selected_csv = str(csv_path)
            st.success(f"ƒê√£ l∆∞u file m·ªõi: {up.name}")

    if st.session_state.selected_csv:
        st.caption(f"üìÑ CSV ƒëang ch·ªçn: `{st.session_state.selected_csv}`")

    # ==== H√†nh vi theo CSV ====
    active_dir = GEOMS_DIR_DEFAULT if (csv_path and csv_path.name.lower() == "test90.csv") else GEOMS_DIR_NEW
    st.session_state.active_geom_dir = str(active_dir)

    if csv_path and csv_path.name.lower() != "test90.csv":
        st.info("B·∫°n ƒëang ch·ªçn CSV kh√°c **test90.csv** ‚Üí c√≥ th·ªÉ ch·∫°y solver ƒë·ªÉ t·∫°o `route_geoms1`.")
        run_col1, run_col2 = st.columns([1,1])
        with run_col1:
            do_run = st.button("üîÅ Ch·∫°y solver & t·∫°o route_geoms1", use_container_width=True)
        with run_col2:
            time_limit = st.number_input("Gi·ªõi h·∫°n th·ªùi gian (gi√¢y)", min_value=20, step=10, value=60)

        if do_run:
            with st.spinner("ƒêang ch·∫°y solver ALNS v√† t·∫°o route_geoms1‚Ä¶"):
                try:
                    _ = _run_solver_with_csv(csv_path, time_limit)  # g·ªçi solver

                    solution_json = _find_and_copy_solution_json()
                    if not solution_json or not solution_json.exists():
                        st.error("Kh√¥ng t√¨m th·∫•y solution JSON sau khi ch·∫°y solver. Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng l∆∞u file trong solver.")
                    else:
                        ok = _build_route_geoms_from_solution(csv_path, solution_json, GEOMS_DIR_NEW)
                        if ok:
                            st.session_state.active_geom_dir = str(GEOMS_DIR_NEW)
                            keys_all = [p.stem for p in GEOMS_DIR_NEW.glob("*.geojson")]
                            st.session_state.cache_view_keys = keys_all
                            st.session_state.last_run_keys = keys_all
                            st.success("ƒê√£ s·∫µn s√†ng hi·ªÉn th·ªã c√°c Route trong route_geoms1.")
                except Exception as e:
                    st.error(f"L·ªói khi ch·∫°y solver/t·∫°o tuy·∫øn: {e}")

    # ==== Danh s√°ch tuy·∫øn theo th∆∞ m·ª•c ƒëang active ====
    active_dir = Path(st.session_state.active_geom_dir)
    st.markdown(f"### 2) Danh s√°ch route trong `<code>{active_dir.name}</code>`", unsafe_allow_html=True)

    if st.button("üëÅÔ∏è Hi·ªÉn th·ªã T·∫§T C·∫¢ route trong th∆∞ m·ª•c ƒëang ch·ªçn", use_container_width=True):
        keys_all = [p.stem for p in active_dir.glob("*.geojson")]
        if keys_all:
            st.session_state.cache_view_keys = keys_all
            st.session_state.last_run_keys = keys_all
            st.success(f"ƒê√£ t·∫£i {len(keys_all)} route.")
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y *.geojson trong th∆∞ m·ª•c.")

    df = _list_cache_pairs(active_dir)
    if df.empty:
        st.warning(f"Ch∆∞a c√≥ file trong th∆∞ m·ª•c `{active_dir}`.")
        pick_names = []
    else:
        df_show = df.copy()
        df_show["geojson_size"] = df_show["geojson_size"].map(_human_size)
        df_show["distance_size"] = df_show["distance_size"].map(_human_size)
        df_show = df_show.rename(columns={
            "route_name":"Route", "key":"Key",
            "has_geojson":"GeoJSON?", "geojson_size":"GeoJSON Size",
            "geojson_mtime":"GeoJSON Modified", "has_distance":"Distance?",
            "distance_size":"Distance Size", "distance_mtime":"Distance Modified",
            "last_mtime":"Last Modified", "distance_km":"Distance (km)",
        })
        order = ["Route","Key","GeoJSON?","GeoJSON Size","GeoJSON Modified",
                 "Distance?","Distance Size","Distance Modified","Last Modified","Distance (km)"]
        df_show = df_show[order]
        st.dataframe(df_show, use_container_width=True, hide_index=True)

        route_to_key = dict(zip(df["route_name"].tolist(), df["key"].tolist()))
        default_routes = [df.loc[df["key"] == k, "route_name"].iloc[0]
                          for k in st.session_state.get("last_run_keys", [])
                          if k in df["key"].values]
        pick_names = st.multiselect("Ch·ªçn route ƒë·ªÉ xem/xo√°:", list(route_to_key.keys()),
                                    default=default_routes, max_selections=30)

        c1, c2 = st.columns([1,1])
        disable_delete = (not pick_names) or (len(pick_names) == len(df))  # ch·∫∑n x√≥a s·∫°ch
        view_btn = c1.button("üëÄ Xem tr√™n b·∫£n ƒë·ªì", use_container_width=True, disabled=not pick_names)
        del_btn  = c2.button("üóëÔ∏è Xo√° route ƒë√£ ch·ªçn", use_container_width=True, disabled=disable_delete)
        if len(pick_names) == len(df) and len(df) > 0:
            st.warning("B·∫°n ƒë√£ ch·ªçn t·∫•t c·∫£ route ‚Äî ƒë·ªÉ an to√†n, kh√¥ng cho ph√©p x√≥a to√†n b·ªô. B·ªè ch·ªçn b·ªõt v√†i route ƒë·ªÉ x√≥a.")

        pick_keys = [route_to_key[n] for n in pick_names]

        if view_btn and pick_keys:
            st.session_state.cache_view_keys = pick_keys
            st.session_state.last_run_keys = pick_keys

        if del_btn and pick_keys:
            ok, err = 0, 0
            for k in pick_keys:
                for ext in (".geojson", ".distance"):
                    p = active_dir / f"{k}{ext}"
                    if p.exists() and p.is_file():
                        try:
                            try: p.chmod(0o666)
                            except Exception: pass
                            p.unlink(); ok += 1
                        except Exception as e:
                            err += 1
                            st.error(f"Kh√¥ng xo√° ƒë∆∞·ª£c {p.name}: {e}")
            st.success(f"ƒê√£ xo√° {ok} file.{' C√≥ l·ªói ·ªü ' + str(err) + ' file.' if err else ''}")
            st.session_state.cache_view_keys = []
            st.session_state.last_run_keys = []
            st.rerun()

# ===== KHU PH·∫¢I: B·∫¢N ƒê·ªí =====
with right:
    active_dir = Path(st.session_state.active_geom_dir)
    st.markdown(f"### 3) B·∫£n ƒë·ªì xem tr∆∞·ªõc (ƒë·ªçc t·ª´ `{active_dir.name}`)")

    m = folium.Map(location=[21.0285,105.8542], zoom_start=12)
    to_draw = [k for k in st.session_state.get("cache_view_keys", []) if (active_dir / f"{k}.geojson").exists()]

    if to_draw:
        pal = ["#1f77b4","#ff7f0e","#2ca02c","#d62728","#9467bd",
               "#8c564b","#e377c2","#7f7f7f","#bcbd22","#17becf"]
        for i, k in enumerate(to_draw):
            gj = active_dir / f"{k}.geojson"
            color = pal[i % len(pal)]
            try:
                geom = json.loads(gj.read_text(encoding="utf-8"))
                folium.GeoJson(
                    data={"type":"Feature","geometry":geom},
                    style_function=lambda feat, col=color: {"color": col, "weight": 4, "opacity": 0.85}
                ).add_to(m)
                coords = geom.get("coordinates", [])
                if coords:
                    mid = coords[len(coords)//2]
                    dkm = _read_distance_km(active_dir, k)
                    route_name = f"Route {i+1}"
                    folium.Marker([mid[1], mid[0]],
                                  popup=f"{route_name} ‚Äî {dkm:.2f} km" if dkm is not None else route_name
                                  ).add_to(m)
            except Exception as e:
                st.error(f"L·ªói ƒë·ªçc {gj.name}: {e}")
    else:
        st.info("Ch∆∞a c√≥ route ƒë·ªÉ hi·ªÉn th·ªã. Ch·ªçn ·ªü b·∫£ng b√™n tr√°i ho·∫∑c b·∫•m **'üëÅÔ∏è Hi·ªÉn th·ªã T·∫§T C·∫¢ route trong th∆∞ m·ª•c ƒëang ch·ªçn'**.")

    st_folium(m, height=620, use_container_width=True, key="map_cache_preview")

    if to_draw:
        sel_dist, total_km = [], 0.0
        for idx, k in enumerate(to_draw):
            dkm = _read_distance_km(active_dir, k)
            if dkm is not None:
                total_km += dkm
            sel_dist.append({"Route": f"Route {idx+1}", "Distance (km)": None if dkm is None else round(dkm, 2)})

        st.markdown("##### T·ªïng kho·∫£ng c√°ch c√°c route ƒëang xem")
        st.dataframe(pd.DataFrame(sel_dist), use_container_width=True, hide_index=True)
        st.metric("T·ªïng qu√£ng ƒë∆∞·ªùng (km)", f"{total_km:.2f}")

st.markdown("<div style='text-align:center;margin-top:1rem'><a href='/' target='_self'>‚¨ÖÔ∏è Quay l·∫°i trang ch√≠nh</a></div>", unsafe_allow_html=True)
